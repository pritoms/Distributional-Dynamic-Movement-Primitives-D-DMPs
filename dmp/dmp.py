import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn.functional as F

def evaluate(dmp, inputs, output):
    """
    Compute the error between a demonstrated trajectory and the reproduction.
    Arguments:
        dmp (DistributionalDMP): The D-DMP model used to perform the reproduction.
        inputs (list[list[float]]): The list of (preprocessed) input values for each step of the demonstration.
        output (torch.Tensor): The list of (preprocessed) output values for each step of the demonstration.
    Returns:
        torch.Tensor: The error between the reproduction and each step of the demonstration.
    """
    # Check if we have intention
    if dmp.intention:
        # Get the intention for the given inputs
        intentions = dmp.compute_intention(inputs)
    else:
        # We don't have intention, just use 0s
        intentions = np.zeros((len(inputs), dmp.output_dim), dmp.dtype)
    # Get the reproduction for the given intentions
    reproduction = dmp.rollout(np.array(intentions))
    # Compute the error as the mean squared error between the reproduction and demonstration
    error = torch.mean(F.mse_loss(torch.tensor(reproduction, dtype=dmp.dtype), output, reduction='none'), dim=1)
    return error


def gaussian_pdf(x, mu, sigma):
    """
    Compute the value of the Gaussian pdf for the given input.
    Arguments:
        x (float): The value to compute the probability for.
        mu (float): The mean of the Gaussian distribution.
        sigma (float): The standard deviation of the Gaussian distribution.
    Returns:
        float: The value of the pdf at x.
    """
    return np.exp(-(x - mu)**2 / (2 * sigma**2))


def initialize_weights(dmp):
    """
    Initialize the weights of a D-DMP model.
    Arguments:
        dmp (DistributionalDMP): The D-DMP model to initialize the weights for.
    """
    # Set all the GPs to have weights sampled from a Gaussian distribution with mean 0 and variance 1
    for gp in dmp.gps:
        gp.w.data = torch.normal(torch.zeros(gp.num_basis), torch.ones(gp.num_basis))


def rollout(dmp, intention=None):
    """
    Reproduce a trajectory given some initial state and a D-DMP.
    Arguments:
        dmp (DistributionalDMP): The D-DMP model used to perform the reproduction.
        intention (np.ndarray): The intention to reproduce. If None, then use 0s.
    Returns:
        np.ndarray: The reproduction of the given intention.
    """
    # Check if we have intention
    if intention is None:
        # We don't have intention, just use 0s
        intention = np.zeros((dmp.output_dim,), dtype=dmp.dtype)
    # Get the columns of the semi-definite representation corresponding to this intention
    columns = dmp.columns(intention).data.numpy()
    # Get the number of samples and timesteps
    num_samples = columns.shape[0]
    num_timesteps = dmp.num_timesteps
    # Set up the desired trajectory
    trajectory = np.zeros((num_samples, num_timesteps, dmp.output_dim), dtype=dmp.dtype)
    # Set the starting state to 0
    trajectory[:, 0, :] = 0

    # Run through the time steps
    for t in range(1, num_timesteps):
        # Get the spring rates from the Gaussian mixture
        k = dmp.k(t).data.numpy()
        # Get the spring rate weights
        w = dmp.spring_rate_weights.data.numpy()
        # Update the current state
        trajectory[:, t, :] = (trajectory[:, t - 1, :] + intention / k) * np.exp(-w / k)
    return trajectory


def sample_trajectory(dmp):
    """
    Sample a trajectory from a given D-DMP model.
    Arguments:
        dmp (DistributionalDMP): The D-DMP model used to generate a trajectory.
    Returns:
        np.ndarray: A trajectory generated by the given D-DMP model.
    """
    # Get the number of samples and timesteps
    num_samples = dmp.num_samples
    num_timesteps = dmp.num_timesteps
    # Set up the desired trajectory
    trajectory = np.zeros((num_samples, num_timesteps, dmp.output_dim), dtype=dmp.dtype)
    # Set the starting state to 0
    trajectory[:, 0, :] = 0

    # Run through the time steps
    for t in range(1, num_timesteps):
        # Get the spring rates from the Gaussian mixture
        k = dmp.k(t).data.numpy()
        # Get the spring rate weights
        w = dmp.spring_rate_weights.data.numpy()
        # Get the projection matrix from the Gaussian mixture
        P = dmp.projection_matrix(t).data.numpy()
        # Get the projection matrix weights
        beta = dmp.projection_matrix_weights.data.numpy()
        # Get the intention for this timestep
        intention = np.sum(P * beta, axis=2).T
        # Update the current state
        trajectory[:, t, :] = (trajectory[:, t - 1, :] + intention / k) * np.exp(-w / k)
    return trajectory


class DistributionalDMP(object):
    """
    This class implements a D-DMP system. It contains the necessary methods to learn a model, plan trajectories, and evaluate the reproductions.
    """
    def __init__(self, input_dim, output_dim, num_basis=20, basis_stddev=0.5,
                 num_samples=10, intention=False, columnspace=False, model=None):
        """
        Initialize a DistributionalDMP object.
        Arguments:
            input_dim (int): The dimension of the input.
            output_dim (int): The dimension of the output.
            num_basis (int): The number of basis functions for each GP.
            basis_stddev (float): The standard deviation of the basis functions.
            num_samples (int): The number of samples to use.
            intention (bool): Whether or not to learn the semi-definite representation based on intention.
            columnspace (bool): Whether or not to learn the semi-definite representation based on the column space.
            model (ColumnSpace): A ColumnSpace object to use for learning the semi-definite representation.
        """
        # Set the input and output dimensions
        self.input_dim = input_dim
        self.output_dim = output_dim
        # Set whether or not we have an intentional D-DMP
        self.intention = intention
        # Set whether or not we are in column space
        self.columnspace = columnspace
        # Default the training data to None
        self.train_inputs = None
        self.train_outputs = None
        # Set the number of samples to use
        self.num_samples = num_samples
        # Set the type used for computations
        self.dtype = torch.float64
        
        # Check if we are using a ColumnSpace object
        if columnspace:
            # Check that we were passed a ColumnSpace object
            if model is None:
                raise ValueError('Please provide a ColumnSpace model!')
            # Use the provided model
            self.model = model
        else:
            # Create a model to learn the semi-definite representation
            self.model = torch.nn.Sequential(
                torch.nn.Linear(input_dim, num_basis),
                torch.nn.ReLU(),
                torch.nn.Linear(num_basis, output_dim)
            )
        # Initialize the projection matrix weights - we keep one for each output dimension
        self.projection_matrix_weights = torch.nn.Parameter(torch.normal(torch.zeros((num_basis, self.output_dim)), torch.ones((num_basis, self.output_dim))).type(self.dtype))
        # Get the semi-definite representation from the model
        psi = self.model(torch.zeros((1, input_dim), dtype=self.dtype)).squeeze()
        # Create GPs for each column of the semi-definite representation
        self.gps = nn.ModuleList([GaussianProcess(1, 1, basis_stddev=basis_stddev, num_basis=num_basis) for _ in range(psi.shape[0])])
        # Initialize the spring rate weights - we keep one for each output dimension
        self.spring_rate_weights = torch.nn.Parameter(torch.normal(torch.zeros(self.output_dim), torch.ones(self.output_dim)).type(self.dtype))
        # Initialize the weights
        initialize_weights(self)

    def compute_intention(self, inputs):
        """
        Compute the intention based on the current state and the given inputs.
        Arguments:
            inputs (list[list[float]]): The list of (preprocessed) input values for each step of the demonstration.
        Returns:
            np.ndarray: The list of intentions for each step of the demonstration.
        """
        # Convert to a nested numpy array
        inputs = np.array(inputs)
        # Reshape the inputs
        inputs = inputs.reshape(inputs.shape[0], 1, self.input_dim)
        # Get the intention for each timestep
        intention = []
        for i in range(len(inputs)):
            intention.append(self.transfer_learning_model(torch.tensor(inputs[i]).type(self.dtype)).detach().numpy())
        return np.array(intention)

    def compute_sdr(self, intention):
        """
        Compute the semi-definite representation corresponding to the given intention.
        Arguments:
            intention (np.ndarray): The intention to compute the semi-definite representation for.
        Returns:
            np.ndarray: The desired semi-definite representation.
        """
        return self.columns(intention).data.numpy()

    def columns(self, intention):
        """
        Compute the columns of the semi-definite representation corresponding to the given intention.
        Arguments:
            intention (np.ndarray): The intention to compute the columns of the semi-definite representation for.
        Returns:
            np.ndarray: The columns of the semi-definite representation.
        """
        # Check if we are using a ColumnSpace object
        if self.columnspace:
            # Use the model to compute the columns
            return self.model(torch.tensor(intention).type(self.dtype))
        # Compute the columns independently
        columns = []
        for i in range(len(self.gps)):
            gp = self.gps[i]
            columns.append(gp(torch.tensor(intention[i]).view(-1, 1)).view(-1))
        return torch.stack(columns, dim=1)

    def evaluate(self, inputs, output, plot=False):
        """
        Compute the error between a demonstrated trajectory and the reproduction.
        Arguments:
            inputs (list[list[float]]): The list of (preprocessed) input values for each step of the demonstration.
            output (torch.Tensor): The list of (preprocessed) output values for each step of the demonstration.
            plot (bool): Whether or not to plot the resulting comparison.
        Returns:
            torch.Tensor: The error between the reproduction and each step of the demonstration.
        """
        # Check if we have intention
        if self.intention:
            # Get the intention for the given inputs
            intentions = self.compute_intention(inputs)
        else:
            # We don't have intention, just use 0s
            intentions = np.zeros((len(inputs), self.output_dim), self.dtype)
        # Get the reproduction for the given intentions
        reproduction = self.rollout(intentions)
        # Compute the MSE
        error = torch.mean(F.mse_loss(torch.tensor(reproduction, dtype=self.dtype), output, reduction='none'), dim=1)
        # Check if we want to plot the result
        if plot:
            # Get the ax used for plotting
            ax = plt.gca()
            # Plot the demonstrated trajectory as a solid blue line
            ax.plot(np.arange(0, len(reproduction)), output.detach().numpy(), color='b', linewidth=1.5)
            # Plot the reproduction as a dashed red line
            ax.plot(np.arange(0, len(reproduction)), reproduction, 'r--', linewidth=1.5)
            # Get the title based on whether we have intention
            if self.intention:
                # Set the title
                plt.title('Demonstrated Trajectory vs Reproduction')
            else:
                # Set the title
                plt.title('Desired Trajectory vs Reproduction')
            # Turn on the legend
            ax.legend(['Trajectory', 'Reproduction'])
        return error

    def k(self, t):
        """
        Compute the spring rates at the given time step based on the learned Gaussian mixture model.
        Arguments:
            t (int): The timestep to compute the spring rates for.
        Returns:
            torch.Tensor: The computed spring rates for the given timestep.
        """
        # Get the normalization constant for the weights
        alpha = torch.sum(self.spring_rate_weights, dim=1)
        # Get the weights divided by the normalization constant
        w = self.spring_rate_weights / alpha
        # Get the spring rates from the gaussian mixture model
        k = torch.sum(w * self.gaussian_mixture_model.mu(t), dim=1)
        return k

    def learn(self, inputs, outputs):
        """
        Learn the parameters of the D-DMP model.
        Arguments:
            inputs (list[list[float]]): The list of (preprocessed) input values for each step of the demonstration.
            outputs (list[list[float]]): The list of (preprocessed) output values for each step of the demonstration.
        """
        # Check if we have intention
        self.intention = inputs is not None
        # Set the training data
        if self.intention:
            self.train_inputs = inputs
        self.train_outputs = outputs
        # Initialize the weights
        initialize_weights(self)
        # Learn the parameters
        train(self, inputs, outputs)
        # Get the normalized projection matrix weights
        alpha = torch.sum(self.projection_matrix_weights, dim=1)
        self.projection_matrix_weights /= alpha

    def project(self, sdr):
        """
        Project the given semi-definite representation into the output space.
        Arguments:
            sdr (np.ndarray): The semi-definite representation to project into the output space.
        Returns:
            np.ndarray: The projected semi-definite representation.
        """
        # Check if we are in column space
        if self.columnspace:
            # Compute the columns for the given intention
            y = self.columns(sdr).data.numpy()
            # Compute the projected output
            x = np.transpose(y, (0, 2, 1)).dot(self.w.detach().numpy())
        else:
            # Compute the columns for the given intention
            y = self.compute_sdr(sdr)
            # Compute the projected output
            x = np.transpose(y, (0, 2, 1)) @ np.transpose([gp.w.detach().numpy() for gp in self.gps])
        return x

    def rollout(self, intention=None):
        """
        Reproduce a trajectory given some initial state and a D-DMP.
        Arguments:
            intention (np.ndarray): The intention to reproduce. If None, then use 0s.
        Returns:
            np.ndarray: The reproduction of the given intention.
        """
        # Check if we have intention
        if intention is None:
            # We don't have intention, just use 0s
            intention = np.zeros((self.output_dim,), dtype=self.dtype)
        # Get the columns of the semi-definite representation corresponding to this intention
        columns = self.columns(intention).data.numpy()
        # Get the number of samples and timesteps
        num_samples = columns.shape[0]
        num_timesteps = self.num_timesteps
        # Set up the desired trajectory
        trajectory = np.zeros((num_samples, num_timesteps, self.output_dim), dtype=self.dtype)
        # Set the starting state to 0
        trajectory[:, 0, :] = 0

        # Run through the time steps
        for t in range(1, num_timesteps):
            # Get the spring rates from the Gaussian mixture
            k = self.k(t).data.numpy()
            # Get the spring rate weights
            w = self.spring_rate_weights.data.numpy()
            # Update the current state
            trajectory[:, t, :] = (trajectory[:, t - 1, :] + intention / k) * np.exp(-w / k)
        return trajectory

    def sample_trajectory(self):
        """
        Sample a trajectory from a given D-DMP model.
        Returns:
            np.ndarray: A trajectory generated by the given D-DMP model.
        """
        # Get the number of samples and timesteps
        num_samples = self.num_samples
        num_timesteps = self.num_timesteps
        # Set up the desired trajectory
        trajectory = np.zeros((num_samples, num_timesteps, self.output_dim), dtype=self.dtype)
        # Set the starting state to 0
        trajectory[:, 0, :] = 0

        # Run through the time steps
        for t in range(1, num_timesteps):
            # Get the spring rates from the Gaussian mixture
            k = self.k(t).data.numpy()
            # Get the spring rate weights
            w = self.spring_rate_weights.data.numpy()
            # Get the projection matrix from the Gaussian mixture
            P = self.projection_matrix(t).data.numpy()
            # Get the projection matrix weights
            beta = self.projection_matrix_weights.data.numpy()
            # Get the intention for this timestep
            intention = np.sum(P * beta, axis=2).T
            # Update the current state
            trajectory[:, t, :] = (trajectory[:, t - 1, :] + intention / k) * np.exp(-w / k)
        return trajectory


class ColumnSpace(object):
    def __init__(self, input_dim, output_dim, num_basis=20, basis_stddev=0.5, num_samples=10, dtype=torch.float64, device='cpu'):
        # Set the input and output dimensions
        self.input_dim = input_dim
        self.output_dim = output_dim
        # Set the number of samples to use
        self.num_samples = num_samples
        # Set the type and device used for computations
        self.dtype = dtype
        self.device = device
        # Create the model to learn the semi-definite representation
        self.model = torch.nn.Sequential(
            torch.nn.Linear(input_dim, num_basis),
            torch.nn.ReLU(),
            torch.nn.Linear(num_basis, output_dim)
        )

    def compute_sdr(self, intention):
        return self.columns(intention).data.numpy()

    def columns(self, intention):
        return self.model(torch.tensor(intention).type(self.dtype))

    def project(self, sdr):
        # Check if we are in column space
        y = self.compute_sdr(sdr)
        # Compute the projected output
        x = np.transpose(y, (0, 2, 1)) @ np.transpose([gp.w.detach().numpy() for gp in self.gps])
        return x

    def train(self, inputs, outputs):
        # Train the model
        self.model.train()
        for i in range(len(outputs)):
            # Forward pass through the model
            y = self.model(torch.tensor(inputs[i]).type(self.dtype))
            # Get the loss
            loss = torch.mean((y - torch.tensor(outputs[i]).type(self.dtype).view(-1, 1, self.output_dim))**2)
            # Zero the gradients
            self.model.zero_grad()
            # Backward pass through the model
            loss.backward()
            # Update the gradients
            self.optimizer.step()
